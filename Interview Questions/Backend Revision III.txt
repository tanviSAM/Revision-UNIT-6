Q1 What is Caching? How can you save money with Caching?
    A cache is where your computer would store regularly accessed files for a limited amount until a certain requirement
    is met. A computer has many caches for different purposes. An example is web browsers storing frequently accessed web
    pages. By storing a file close to the end user, the access time is negligible.

    Caching can save money as
    - Cache servers can unload the burden on networks by creating copies of frequently visited sites and downloaded files
      at a local level.
    - VSAT users can benefit from reduced bandwidth usage – reducing costs and improving the end-user experience.
    - Prices for cache servers have plummeted in recent years, due to falling hardware and memory costs.

Q2 What is load balancing?
    Load balancing refers to efficiently distributing incoming network traffic across a group of backend servers, also known
    as a server farm or server pool.

    Modern high‑traffic websites must serve hundreds of thousands, if not millions, of concurrent requests from users or
    clients and return the correct text, images, video, or application data, all in a fast and reliable manner. To
    cost‑effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers.

    A load balancer acts as the “traffic cop” sitting in front of your servers and routing client requests across all servers
    capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server
    is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the
    remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send
    requests to it.

Q3 What is CAP Theorem?
    The CAP theorem (also called Brewer’s theorem) states that a distributed database system can only guarantee two out of these
    three characteristics: Consistency, Availability, and Partition Tolerance.

    - Consistency
        A system is said to be consistent if all nodes see the same data at the same time.
        Simply, if we perform a read operation on a consistent system, it should return the value of the most recent write
        operation.
        This means that, the read should cause all nodes to return the same data, i.e., the value of the most recent write.

    - Availability
        Availability in a distributed system ensures that the system remains operational 100% of the time. Every request gets
        a (non-error) response regardless of the individual state of a node.
        Note: this does not guarantee that the response contains the most recent write.
        The figure on the left illustrates an “unavailable” system.

    - Partition Tolerance
        This condition states that the system does not fail, regardless of if messages are dropped or delayed between nodes
        in a system.
        Partition tolerance has become more of a necessity than an option in distributed systems. It is made possible by
        sufficiently
        replicating records across combinations of nodes and networks.

Q4 What is PACELC Theorem?
    The PACELC theorem is an extension of the CAP theorem, stating that if there is partitioning (P) in the network, you should
    choose between availability (A) and consistency (C), else (E), you should select between latency (L) and consistency (C).

Q5 What is Eventual Consistency?
    Eventual Consistency is a guarantee that when an update is made in a distributed database, that update will eventually be
    reflected in all nodes that store the data, resulting in the same response every time the data is queried.

Q6 What is Strong Consistency?
    To have strong consistency, developers must compromise on the scalability and performance of their application. Simply
    put, data has to be locked during the period of update or replication process to ensure that no other processes are
    updating the same data.

Q7 What are the different types of databases?
    Types of databases
        - Centralised database
        - Distributed database
        - Personal database
        - End-user database
        - Commercial database
        - NoSQL database
        - Operational database
        - Relational database
        - Cloud database
        - Object-oriented database
        - Graph database

Q8 What are message queues?

Q9 Which service by Amazon Web Services (AWS) can you use for Queues?

Q10 What is Pub Sub ?

Q11 What are webhooks?

Q12 What is Docker? Why do we use it?

Q13 What is S3 Service in AWS?

Q14 What is EC2 Instance in AWS?

Q15 What is Cloudfront in AWS?

Q16 What is Route 53 In AWS?

Q17 What are ELBs in AWS?

Q18 What is TLS?

Q19 What is the difference HTTPS vs HTTP?

Difference Between HTTP & HTTPS
-	HTTP stands for HyperText Transfer Protocol.
    HTTPS for HyperText Transfer Protocol Secure.

-	In HTTP the url begins with “http://”.
    In HTTPsthe url begins with “https://”.
    
-   HTTP faster than HTTPS.
    HTTPS slower than HTTP.

-   HTTP is considered to be unsecure.
    HTTPS is considered as secure.
    
-   HTTP does not improve search ranking.
    HTTPS helps in improving search ranking.

-   HTTP works at Application Layer.
    HTTPS works at Transport Layer.
	
-   Encryption is absent in HTTP.
    Encryption is present in HTTPS.
	
-	HTTP does not require any certificates.
    HTTPS needs SSL(Secure Sockets Layer) Certificates.

Q20 What is a reverse proxy?
